# D2E with AGAC Configuration for DM Control
algorithm:
  # General parameters
  max_steps: 2000000
  eval_freq: 4000
  num_epochs: 2000
  num_episodes_eval: 1
  train_freq: 2048
  discrete: False
  precision: 32
  gpu: 0
  seed: 1234
  
  # Environment parameters
  task: "dmc_cheetah_run"
  action_repeat: 2
  envs: 1
  envs_parallel: "none"
  eval_eps: 1
  
  # Training control
  train_every: 5
  log_every: 100
  train_steps: 1
  save_fre: 2
  expl_until: 0
  
  # Memory parameters
  prefill: 100000
  length: 1000
  policy_reply_buffer_size: 500
  policy_reply_buffer_prefill_batch: 100
  sequence_size: 20
  batch_size: 100
  
  # File handling
  load_prefill: 0
  load_model: 0

logging:
  save_models: True
  save_models_freq: 100000
  use_neptune: False
  experiment_name: "D2E-AGAC-DMControl"
  neptune_user_name: "zsheikhb"
  neptune_project_name: "AIME"
  log_grid: False
  
  # Logging keys
  log_keys_video: ['s2']
  log_keys_sum: '^$'
  log_keys_mean: '^$'
  log_keys_max: '^$'

reinforcement_learning:
  # AGAC policy parameters
  actor_learning_rate: 0.0003
  critic_learning_rate: 0.0003
  adversary_learning_rate: 0.00009
  layers_dim: [256, 256]
  adv_layers_dim: [256, 128]
  discount: 0.99
  batch_size: 256
  lambda_gae: 0.95
  intrinsic_reward_coefficient: 0.001
  entropy_coefficient: 0.01
  clipping_epsilon: 0.2
  value_loss_clip: 0.2
  value_loss_coeff: 0.25
  adversary_loss_coeff: 0.0001
  cnn_extractor: False
  layers_num_channels: [32, 32, 32]
  nb_stack: 1
  clip_grad_norm: 0.5
  episodic_count_coefficient: 0.0

world_model:
  # D2E world model parameters
  prior_alpha: 7.0
  prior_beta: 1.0
  hidden_transit: 10
  number_of_mixtures: 3
  weight_decay: 1e-5
  n_channel: 3
  max_components: 2
  latent_dim: 10
  hidden_dim: 10
  lr: 1e-4
  beta: 1.0
  lambda_img: 1.0
  lambda_latent: 3.0
  n_critic: 3
  grad_clip: 0.5
  img_disc_channels: 16
  img_disc_layers: 5
  latent_disc_layers: 3
  use_actnorm: True
  
  # Image parameters
  image_width: 84
  image_height: 84
  
  # Environment parameters
  max_episode_steps: 1000
  discount: 0.99